{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40969fd-9b56-4068-8d6b-4b85dcf2e9e6",
   "metadata": {},
   "source": [
    "# AWS S3 Buckets: Uploading and Downloading\n",
    "\n",
    "AWS S3 buckets provide scalable, secure, reliable data storage in the AWS cloud.\n",
    "\n",
    "AWS provides software to interact with the S3 API:\n",
    "  - [AWS CLI](https://aws.amazon.com/cli/) for access from the command line\n",
    "  - [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) for programmatic Python access\n",
    "\n",
    "S3 Buckets may be **public** or **private**\n",
    "\n",
    "---\n",
    "\n",
    "## 1 Public S3 Buckets\n",
    "\n",
    "### 1.1 Downloading and Uploading from the command line with `AWS CLI`\n",
    "- does not require authentication\n",
    "- if not authenticating, requires use of the `--no-sign-request` argument\n",
    "\n",
    "The `aws s3 cp` command works for downloading or uploading from/to S3:\n",
    "\n",
    "`aws s3 cp source_path destination_path`\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.1.1 Attempt downloading an example file from a public S3 bucket without using the `--no-sign-request` argument**\n",
    "\n",
    "- This will cause an error unless you have previously configured the aws-cli with your AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dcc04-055b-4a16-afad-e2c7d915a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://asf-jupyter-data-west/S3_example/example.txt example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b65fda-05cb-44a9-8e75-a4a7f8548042",
   "metadata": {},
   "source": [
    "#### **1.1.2 Run the `aws s3 cp` command again, adding the `--no-sign-request` argument**\n",
    "\n",
    "- Look for the downloaded file in the file browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7473c29-eb55-45a5-add8-d05a629e2347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp --no-sign-request s3://asf-jupyter-data-west/S3_example/example.txt example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe64ab1-271d-41b4-ac25-7769b90f925b",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.1.3 Swap the source and destination paths to upload the file to the same location**\n",
    "\n",
    "- uploading the file will overwrite the copy in the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c97326-a8cf-418e-bdde-73f04cc592c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp --no-sign-request example.txt s3://asf-jupyter-data-west/S3_example/example.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254845f4-1571-4fee-b010-cb56403ae932",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.1.4 There is an 8MB file size limit when uploading to S3 if not authenticated, even to a public bucket, using the `--no-sign-request` argument.**\n",
    "\n",
    "- Files larger than 8MB default to a multi-part upload, which anonymous users do not have privileges to perform\n",
    "- This size limitation **does not apply when downloading** from S3\n",
    "\n",
    "**Create a 9MB file and try to upload it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104c1a9-521a-4528-b08a-6d4e389da246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head -c 9MB /dev/urandom > too_big_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0678ead-f250-4d62-94bb-829599965cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws --no-sign-request s3 cp too_big_file s3://asf-jupyter-data-west/S3_example/too_big_file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a320f4-c47b-4ad7-865b-e7ab6cab75e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2 Downloading and Uploading in Python with `boto3`\n",
    "\n",
    "You can build S3 access into your Python scripts and automated workflows with `boto3`\n",
    "\n",
    "#### **1.2.1 To prepare for the following steps, delete the local copy of `example.txt`, which we previously downloaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1f8ab-e610-4299-8800-4b17ea7dd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "example_path = Path.cwd()/\"example.txt\"\n",
    "example_path.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d72e7c-3a18-4fe8-9031-c6e99cc15140",
   "metadata": {},
   "source": [
    "#### **1.2.2 Run the following code cell to attempt downloading `example.txt` with `boto3` from a public S3 bucket without declaring an unsigned signature or providing credentials** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90d77e-516a-4cb1-8990-70ace17aa488",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = \"asf-jupyter-data-west\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# objects in S3 bucket storage are called keys\n",
    "example_key = \"S3_example/example.txt\"\n",
    "\n",
    "bucket.download_file(example_key, example_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2905b-8fb2-492a-bf14-2de7e36ce17f",
   "metadata": {},
   "source": [
    "That didn't work; we received a `NoCredentialsError`. We need to provide our AWS credentials or declare ourselves as anonymous users.\n",
    "\n",
    "---\n",
    "#### **1.2.2 Try this again, but declare yourself anonymous by providing the config signature version: `UNSIGNED`**\n",
    "\n",
    "It may take a few moments for the file to appear in the file browser. You can hit the file browser's refresh button to make it appear sooner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0296f-9887-4a8b-8d44-2abe39ad1bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "s3 = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "bucket_name = \"asf-jupyter-data-west\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "bucket.download_file(example_key, example_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddf39d-d691-4605-a0e4-3b78c6c7025a",
   "metadata": {},
   "source": [
    "#### **1.2.3 Upload `example.txt` with `boto3`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e9500-e262-4a4d-9e3e-c6a363a8c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.upload_file(example_path, example_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23f4d7-4320-4f8a-b02d-0408a746f8d5",
   "metadata": {},
   "source": [
    "#### **1.2.4 Create a 9MB file and try uploading it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf05ee3-6d4b-4be7-8521-31deb346892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "too_big_path = Path.cwd()/\"too_big_file.txt\"\n",
    "!head -c 9MB /dev/urandom > $too_big_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414df3b-fa01-4358-8dfc-327fc1493c59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "too_big_key = \"S3_example/too_big_file.txt\"\n",
    "\n",
    "bucket.upload_file(too_big_path, too_big_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f23331-2105-4b28-b5d0-f699346fb711",
   "metadata": {},
   "source": [
    "Once again, we cannot upload this 9MB file because we cannot initiate a multi-part upload as an anonymous user.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.3 Configuring you AWS-cli to add your AWS credentials**\n",
    "\n",
    "- You will need an `AWS Access Key ID` and `AWS Secret Access Key` from an AWS IAM Role with permissions to access any needed private S3 Buckets\n",
    "  - https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey\n",
    "\n",
    "These credentials are discoverable by both `aws-cli` and `boto3` and will allow you to:\n",
    "- upload files larger than 8MB to public S3 buckets (without setting any special permissions)\n",
    "- access private buckets (if your AWS IAM user has permission)\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.3.1 Open a launcher, Drag this notebook tab into split-screen mode, and open a terminal:**\n",
    "\n",
    "<img src=\"https://opensarlab-docs.asf.alaska.edu/opensarlab-notebook-assets/workshops/nisar_early_adopters/open_terminal.gif\" width=75%/>\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.3.2 Configure AWS**\n",
    "\n",
    "- Enter `aws configure` in the terminal\n",
    "  - Enter your AWS Access Key ID\n",
    "  - Enter your AWS Secret Access Key\n",
    "  - Enter a region (\"us-west-2\" for ASF data access)\n",
    "  - Enter \"json\" as an output format\n",
    "\n",
    "<img src=\"https://opensarlab-docs.asf.alaska.edu/opensarlab-notebook-assets/workshops/nisar_early_adopters/aws_creds.gif\" width=75%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8724eb7-dd36-4e54-9d4e-bbe54a28a730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
