{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40969fd-9b56-4068-8d6b-4b85dcf2e9e6",
   "metadata": {},
   "source": [
    "# AWS S3 Buckets: Uploading and Downloading\n",
    "\n",
    "AWS S3 buckets provide scalable, secure, reliable data storage in the AWS cloud.\n",
    "\n",
    " - **This notebook will throw some errors for demonstration purposes. Do not be alarmed.**\n",
    "\n",
    "AWS provides software to interact with the S3 API:\n",
    "  - [AWS CLI](https://aws.amazon.com/cli/) for access from the command line\n",
    "    - There are 2 major version of awscli, v1 and v2, which use different authentication paradigms.\n",
    "      - This notebook covers awscli v1\n",
    "      - awscli v2 content will be added at a later date\n",
    "  - [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) for programmatic Python access\n",
    "\n",
    "S3 Buckets may be **public** or **private**\n",
    "\n",
    "---\n",
    "\n",
    "## **1 Downloading from Public S3 Buckets**\n",
    "\n",
    "\n",
    "### **1.1 Downloading from the command line with `AWS CLI`**\n",
    "- does not require authentication\n",
    "- if not authenticating, requires use of the `--no-sign-request` argument\n",
    "\n",
    "The `aws s3 cp` command works for downloading or uploading from/to S3:\n",
    "\n",
    "`aws s3 cp source_path destination_path`\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.1.1 Attempt downloading an example file from a public S3 bucket without using the `--no-sign-request` argument**\n",
    "\n",
    "- This will cause an error unless you have previously configured the aws-cli with your AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dcc04-055b-4a16-afad-e2c7d915a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://asf-jupyter-data-west/S3_example/example.txt example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b65fda-05cb-44a9-8e75-a4a7f8548042",
   "metadata": {},
   "source": [
    "#### **1.1.2 Run the `aws s3 cp` command again, adding the `--no-sign-request` argument**\n",
    "\n",
    "- Look for the downloaded file in the file browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7473c29-eb55-45a5-add8-d05a629e2347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp --no-sign-request s3://asf-jupyter-data-west/S3_example/example.txt example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a320f4-c47b-4ad7-865b-e7ab6cab75e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **1.2 Downloading in Python with `boto3`**\n",
    "\n",
    "You can build S3 access into your Python scripts and automated workflows with `boto3`\n",
    "\n",
    "#### **1.2.1 To prepare for the following steps, delete the local copy of `example.txt`, which we previously downloaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1f8ab-e610-4299-8800-4b17ea7dd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "example_path = Path.cwd()/\"example.txt\"\n",
    "example_path.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d72e7c-3a18-4fe8-9031-c6e99cc15140",
   "metadata": {},
   "source": [
    "#### **1.2.2 Run the following code cell to attempt downloading `example.txt` with `boto3` from a public S3 bucket without declaring an unsigned signature or providing credentials** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90d77e-516a-4cb1-8990-70ace17aa488",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = \"asf-jupyter-data-west\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# objects in S3 bucket storage are called keys\n",
    "example_key = \"S3_example/example.txt\"\n",
    "\n",
    "bucket.download_file(example_key, example_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2905b-8fb2-492a-bf14-2de7e36ce17f",
   "metadata": {},
   "source": [
    "That didn't work; we received a `NoCredentialsError`. We need to provide our AWS credentials or declare ourselves as anonymous users.\n",
    "\n",
    "---\n",
    "#### **1.2.2 Try this again, but declare yourself anonymous by providing the config signature version: `UNSIGNED`**\n",
    "\n",
    "It may take a few moments for the file to appear in the file browser. You can hit the file browser's refresh button to make it appear sooner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0296f-9887-4a8b-8d44-2abe39ad1bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "s3 = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "bucket_name = \"asf-jupyter-data-west\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "bucket.download_file(example_key, example_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f23331-2105-4b28-b5d0-f699346fb711",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **2 Configuring awscli v1 to add your AWS credentials**\n",
    "\n",
    "- You will need an `AWS Access Key ID` and `AWS Secret Access Key` from an AWS IAM Role with permissions to access any needed private S3 Buckets\n",
    "  - https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey\n",
    "\n",
    "These credentials are discoverable by both `aws-cli` and `boto3` and will allow you to:\n",
    "- upload files to public S3 buckets if you have an access key for the account and your IAM user has permissions\n",
    "- access private buckets if you have an access key for the account and your IAM user has permissions\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.1 Open a launcher, Drag this notebook tab into split-screen mode, and open a terminal:**\n",
    "\n",
    "<img src=\"https://opensarlab-docs.asf.alaska.edu/opensarlab-notebook-assets/workshops/nisar_early_adopters/open_terminal.gif\" width=75%/>\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.2 Configure your default AWS profile**\n",
    "\n",
    "- Enter `aws configure` in the terminal\n",
    "  - Enter your AWS Access Key ID\n",
    "  - Enter your AWS Secret Access Key\n",
    "  - Enter a region (\"us-west-2\" for ASF data access)\n",
    "  - Enter \"json\" as an output format\n",
    "\n",
    "<img src=\"https://opensarlab-docs.asf.alaska.edu/opensarlab-notebook-assets/workshops/nisar_early_adopters/aws_creds.gif\" width=75%/>\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.3 Configure a non-default AWS profile**\n",
    "\n",
    "Adding profiles will allow you to access buckets in different AWS accounts using different sets of credentials\n",
    "\n",
    "**Repeat the steps in 1.3.2, changing the following:**\n",
    "- change `aws configure` to  `aws configure --profile your_profile_name`\n",
    "    - replace `your_profile_name` with your chosen profile name\n",
    "    \n",
    "This will produce a `~/.aws/credentials` file that looks something like this:\n",
    "\n",
    "```\n",
    "[default]\n",
    "aws_access_key_id = key_id_for_account_1\n",
    "aws_secret_access_key = access_key_for_account_1\n",
    "\n",
    "[profile_name_for_account_2]\n",
    "aws_access_key_id = key_id_for_account_2\n",
    "aws_secret_access_key = access_key_for_account_2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe64ab1-271d-41b4-ac25-7769b90f925b",
   "metadata": {},
   "source": [
    "---\n",
    "## **3 Uploading to S3 Buckets with Credentials**\n",
    "\n",
    "### **3.1 Uploading with `awscli`**\n",
    "\n",
    "#### **3.1.1 Swapping the source and destination paths in our previous awscli download command will upload the file to the same location**\n",
    "\n",
    "- Even though the bucket is public, you will not be able to write to it unless the IAM user owning your Access Key has permission\n",
    "- uploading the file will overwrite the copy in the S3 bucket\n",
    "\n",
    "**The command below uses your default AWS profile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c97326-a8cf-418e-bdde-73f04cc592c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp example.txt s3://asf-jupyter-data-west/S3_example/example.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2524e9a-96c9-4972-8e00-6e10f7242195",
   "metadata": {},
   "source": [
    "---\n",
    "#### **3.1.2 If you added your credentials under a profile, you will need to use the `--profile` argument and provide your profile name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df3beb-4a05-45ae-b69e-0b89add01d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 --profile osl cp example.txt s3://asf-jupyter-data-west/S3_example/example.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddf39d-d691-4605-a0e4-3b78c6c7025a",
   "metadata": {},
   "source": [
    "---\n",
    "### **3.2 Uploading with `boto3`**\n",
    "\n",
    "#### **3.2.1 Upload `example.txt` with `boto3`**\n",
    "\n",
    "- if your default AWS profile is not configured to access the bucket, the next command will fail (this is okay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abb01e-d553-4351-b971-42ade52558c0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = \"asf-jupyter-data-west\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# objects in S3 bucket storage are called keys\n",
    "example_key = \"S3_example/example.txt\" \n",
    "\n",
    "bucket.upload_file(example_path, example_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b0900-c8b2-4da3-8df2-592c1fce76c8",
   "metadata": {},
   "source": [
    "---\n",
    "#### **3.2.2 If you added your credentials under a profile, you will need instantiate a `boto3` session with your profile name**\n",
    "- `session = boto3.Session(profile_name='your _profile_name')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8724eb7-dd36-4e54-9d4e-bbe54a28a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = \"asf-jupyter-data-west\"\n",
    "session = boto3.Session(profile_name='osl')\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# objects in S3 bucket storage are called keys\n",
    "example_key = \"S3_example/example.txt\" \n",
    "\n",
    "s3.upload_file(example_path, bucket_name, example_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e6601-2ed4-41cb-ad53-5f216770d2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
